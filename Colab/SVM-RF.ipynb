{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"18y1I7MxXk2Zc5RucthT4r3g-pyXDJim0","authorship_tag":"ABX9TyN6PNKVEvJ4SM7tCTbBRrbm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uk7Kz4d76rE4","executionInfo":{"status":"ok","timestamp":1680467708117,"user_tz":-180,"elapsed":11154,"user":{"displayName":"Bedri Keskin","userId":"15100244906447267406"}},"outputId":"0bae28ba-34e4-4fa8-aa2d-47000564bb05"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Model accuracy: 100.00%\n"]}],"source":["import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from google.colab import drive\n","import joblib\n","\n","drive.mount('/content/gdrive')\n","\n","path_Algol = '/content/gdrive/MyDrive/Doktora/Python/Algol_Noisy'\n","Algol_files = [os.path.join(path_Algol, f) for f in os.listdir(path_Algol) if f.endswith('.txt')]\n","data_Algol = []\n","labels_Algol = []\n","\n","for file in Algol_files:\n","  labels_Algol.append(\"Algol\")\n","  fileContent = []\n","  with open(file, 'r') as f:\n","        lines = f.readlines()\n","        for line in lines:\n","            # Satırları ayrıştırın ve x, y koordinatlarını depolayın\n","            x, y = line.strip().split('\\t')\n","            fileContent.append(float(y))\n","  data_Algol.append(fileContent)\n","\n","path_Beta_Lyrae = '/content/gdrive/MyDrive/Doktora/Python/Beta_Lyrae_Noisy'\n","Beta_Lyrae_files = [os.path.join(path_Beta_Lyrae, f) for f in os.listdir(path_Beta_Lyrae) if f.endswith('.txt')]\n","data_Beta_Lyrae = []\n","labels_Beta_Lyrae = []\n","\n","for file in Beta_Lyrae_files:\n","  labels_Beta_Lyrae.append(\"B Lyr\")\n","  fileContent = []\n","  with open(file, 'r') as f:\n","        lines = f.readlines()\n","        for line in lines:\n","            # Satırları ayrıştırın ve x, y koordinatlarını depolayın\n","            x, y = line.strip().split('\\t')\n","            fileContent.append(float(y))\n","  data_Beta_Lyrae.append(fileContent)\n","\n","path_W_UMa = '/content/gdrive/MyDrive/Doktora/Python/W_UMa_Noisy'\n","W_UMa_files = [os.path.join(path_W_UMa, f) for f in os.listdir(path_W_UMa) if f.endswith('.txt')]\n","data_W_UMa = []\n","labels_W_UMa = []\n","\n","for file in W_UMa_files:\n","  labels_W_UMa.append(\"W UMa\")\n","  fileContent = []\n","  with open(file, 'r') as f:\n","        lines = f.readlines()\n","        for line in lines:\n","            # Satırları ayrıştırın ve x, y koordinatlarını depolayın\n","            x, y = line.strip().split('\\t')\n","            fileContent.append(float(y))\n","  data_W_UMa.append(fileContent)\n","\n","# Verileri ve etiketleri numpy dizilerine dönüştürün\n","data = np.array(data_Algol+data_Beta_Lyrae+data_W_UMa)\n","\n","labels = np.array(labels_Algol+labels_Beta_Lyrae+labels_W_UMa)\n","\n","# Verileri eğitim ve test kümelerine ayırın\n","X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n","\n","# Özellik ölçeklendirme\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# RandomForestClassifier sınıflandırıcısını kullanarak modeli eğitin\n","#model = RandomForestClassifier()\n","model = SVC(kernel='rbf', gamma='scale', C=1.0)\n","\n","model.fit(X_train, y_train)\n","#Modeli diske kaydet\n","joblib.dump(model, \"/content/gdrive/MyDrive/Doktora/Python/RandomForest.joblib\")\n","\n","# Test verileri üzerinde model doğruluğunu değerlendirin\n","accuracy = model.score(X_test, y_test)\n","print(\"Model accuracy: {:.2f}%\".format(accuracy * 100))\n","\n"]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","import joblib\n","\n","#file = '/content/gdrive/MyDrive/Doktora/Python/Algol_test/algol1201.txt'\n","#file = '/content/gdrive/MyDrive/Doktora/Python/Algol_test/algol1202.txt'\n","#file = '/content/gdrive/MyDrive/Doktora/Python/Beta_Lyrae_test/beta_lyrae1601.txt'\n","#file = '/content/gdrive/MyDrive/Doktora/Python/Beta_Lyrae_test/beta_lyrae1602.txt'\n","file = '/content/gdrive/MyDrive/Doktora/Python/W_UMa_test/w_uma1621.txt'\n","#file = '/content/gdrive/MyDrive/Doktora/Python/W_UMa_test/w_uma1622.txt'\n","print(file)\n","data_test = []\n","fileContent = []\n","  \n","with open(file, 'r') as f:\n","        lines = f.readlines()\n","        for line in lines:\n","            # Satırları ayrıştırın ve x, y koordinatlarını depolayın\n","            x, y = line.strip().split('\\t')\n","            fileContent.append([float(y)])\n","data_test.append(fileContent)\n","\n","\n","data_test = np.array(data_test)\n","nsamples, nx, ny = data_test.shape\n","data_testReshaped = data_test.reshape((nsamples,nx*ny))\n","\n","scaler = StandardScaler()\n","data_testReshaped = scaler.fit_transform(data_testReshaped)\n","\n","loadedModel = joblib.load(\"/content/gdrive/MyDrive/Doktora/Python/RandomForest.joblib\")\n","\n","loadedModel.predict(data_testReshaped)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vt93QRakGI5L","executionInfo":{"status":"ok","timestamp":1679623477951,"user_tz":-180,"elapsed":623,"user":{"displayName":"Bedri Keskin","userId":"15100244906447267406"}},"outputId":"73e7934e-3804-4f9e-bac8-96e37f7a7e2d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Doktora/Python/W_UMa_test/w_uma1621.txt\n"]},{"output_type":"execute_result","data":{"text/plain":["array(['B Lyr'], dtype='<U5')"]},"metadata":{},"execution_count":10}]}]}